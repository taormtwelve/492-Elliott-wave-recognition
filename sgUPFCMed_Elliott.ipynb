{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, time, datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randrange, shuffle\n",
    "from enchant.utils import levenshtein # pip install pyenchant\n",
    "from pyts.approximation import SymbolicAggregateApproximation # pip install pyts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _________________________ Algorithms _________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def String_representation(X, n_bins):\n",
    "    \n",
    "    C = len(X)\n",
    "    X_norm, S = [[] for _ in range(C)], [[] for _ in range(C)]\n",
    "    \n",
    "    # normalization\n",
    "    for i in range(C):\n",
    "        X_norm[i] = [(Xij - Xij.mean())/Xij.std() for Xij in X[i]]\n",
    "    \n",
    "    # Symbolic Aggregate Approximation\n",
    "    sax = SymbolicAggregateApproximation(n_bins=n_bins, strategy='normal')\n",
    "    for i in range(C):\n",
    "        for xs in X_norm[i]:\n",
    "            S[i].append(''.join(sax.fit_transform([xs])[0]))\n",
    "    return S.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String grammar clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StringGrammarClustering(S, C, m, eta, a, b): # normally (m , eta > 1)  (beta ,a , b > 0)\n",
    "    \n",
    "    N = len(S) # Number of string\n",
    "    V_pos = [i for i in range(len(S))]\n",
    "    shuffle(V_pos)\n",
    "    V_pos = V_pos[:C]\n",
    "    \n",
    "    print('Initial : V_pos(random) =', V_pos)\n",
    "    \n",
    "    # Compute Levenshtein distance between input string j and cluster prototype i (Lev(s_j, sc_i))\n",
    "    Lev = [[0]*N for _ in range(N)]\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i <= j:\n",
    "                Lev[i][j] = levenshtein(S[i],S[j])\n",
    "            else:\n",
    "                Lev[i][j] = Lev[j][i]\n",
    "    \n",
    "    # Compute beta using fuzzy median equation (3)\n",
    "    Med_pos = np.array([sum([Lev[j][k] for k in range(N)]) for j in range(N)]).argmin()\n",
    "    beta = sum([Lev[Med_pos][k] for k in range(N)])/N \n",
    "    \n",
    "    epoch = 1\n",
    "    while True:\n",
    "        \n",
    "        U = [[0]*N for _c in range(C)] # membership matrix [u_ik]_CxN\n",
    "        T = [[0]*N for _c in range(C)] # possibilistic matrix [t_ik]_CxN\n",
    "        \n",
    "        # Update membership and possibilistic\n",
    "        for i in range(C):\n",
    "            for k in range(N):    \n",
    "                \n",
    "                # Update membership value using equation (5)\n",
    "                if k not in V_pos: # string s_k is not prototype(V)\n",
    "                    U[i][k] = 1/sum([(Lev[V_pos[i]][k]/Lev[V_pos[j]][k])**(1/(m-1)) for j in range(C)])\n",
    "\n",
    "                # Update possibilistic value using equation (6)\n",
    "                T[i][k] = math.exp(-b * eta * math.sqrt(C) * Lev[V_pos[i]][k] / beta)\n",
    "            \n",
    "            # Set membership value sc_i = 1 (prototype)\n",
    "            U[i][V_pos[i]] = 1\n",
    "\n",
    "        # Update center string of each cluster i (sc_i) using equation (10)\n",
    "        V_pos_updated = [np.array([sum([(a*U[i][k]**m + b*T[i][k]**eta)*Lev[j][k] for k in range(N)]) for j in range(N)]).argmin() for i in range(C)]\n",
    "        \n",
    "        print('epoch', epoch, end=': ')\n",
    "        print('V_pos =', V_pos_updated)\n",
    "        if V_pos_updated == V_pos:\n",
    "            # return Multi-prototypes\n",
    "            V = []\n",
    "            for i in range(C):\n",
    "                if S[V_pos[i]] not in V:\n",
    "                    V.append(S[V_pos[i]])\n",
    "#             for i in range(C):\n",
    "#                 V.append(S[V_pos[i]])\n",
    "            return V\n",
    "        \n",
    "        V_pos = V_pos_updated.copy()\n",
    "        epoch += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FKNN Classifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FKNN(SC, S_test, C, K = 3, m = 2):\n",
    "    \n",
    "    pred = [[] for _ in range(C)]\n",
    "    \n",
    "    for idx in range(C):\n",
    "        for _s in S_test[idx]:\n",
    "\n",
    "            # lowest levenshtein distance K prototypes\n",
    "            lowest = []\n",
    "            Lev = [[levenshtein(_s, sc_ij) for sc_ij in sc_i] for sc_i in SC]\n",
    "            for _ in range(K):\n",
    "                lev_min = float('inf')\n",
    "                lev_class, lev_idx = -1, -1\n",
    "                for i in range(len(Lev)):\n",
    "                    for j in range(len(Lev[i])):\n",
    "                        if Lev[i][j] < lev_min:\n",
    "                            lev_min = Lev[i][j]\n",
    "                            lev_class = i\n",
    "                            lev_idx = j\n",
    "                lowest.append((lev_class, lev_idx))\n",
    "                Lev[lev_class][lev_idx] = float('inf')\n",
    "\n",
    "            # class prediction\n",
    "            prob = []\n",
    "            for _k in range(K):\n",
    "                dividend, divisor = 0, 0\n",
    "                for (i, j) in lowest:\n",
    "                    lev = levenshtein(SC[i][j], _s)\n",
    "                    if not lev == 0:\n",
    "                        eq = (1/lev)**(1/(m-1))\n",
    "                    else:\n",
    "                        eq = 1\n",
    "\n",
    "                    divisor += eq\n",
    "                    if lowest[_k][0] == i:\n",
    "                        dividend += eq\n",
    "                prob.append(dividend/divisor)\n",
    "            pred[idx].append(lowest[np.array(prob).argmax()][0])            \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy calculation and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, C):\n",
    "    c_matrix = [[0]*C for _ in range(C)]\n",
    "    sum_true = 0\n",
    "    sum_all = 0\n",
    "    for i in range(C):\n",
    "        for p in pred[i]:\n",
    "            c_matrix[p][i] += 1\n",
    "            sum_all += 1\n",
    "            if p == i:\n",
    "                sum_true += 1\n",
    "    print('\\tConfusion Matrix')\n",
    "    for m in c_matrix:\n",
    "        print(f' [ {m[0] : ^5}{m[1] : ^5}{m[2] : ^5}{m[3] : ^5}{m[4] : ^5} ]')\n",
    "    print()\n",
    "    return round(sum_true*100/sum_all, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset\n",
    "File Header : [Date, Open, High, Low, Close, Adj Close, Volume]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, C):\n",
    "    \n",
    "    Elliott_patterns = [[] for _ in range(5)]\n",
    "    pattern = []\n",
    "    file = open(path)\n",
    "    data = file.read().split()\n",
    "    data = [d.split(',') for d in data]\n",
    "\n",
    "    for i, ds in enumerate(data):\n",
    "        if len(ds) == 2:\n",
    "            if not pattern == []:\n",
    "                Elliott_patterns[_y].append(np.array(pattern))\n",
    "            pattern = []\n",
    "\n",
    "            # for C classes recognition\n",
    "            _y = int(ds[1]) - 1 # class number\n",
    "\n",
    "        elif i == len(data) - 1:\n",
    "            Elliott_patterns[_y].append(np.array(pattern))\n",
    "            pattern = []\n",
    "        else:\n",
    "            pattern.append(float(ds[2])) # High price\n",
    "            pattern.append(float(ds[3])) # Low Price\n",
    "#             pattern.append(float(ds[4])) # Close Price\n",
    "    \n",
    "#     Elliott_patterns = [[p for p in ep if len(p) > 40] for ep in Elliott_patterns]\n",
    "\n",
    "    n_spc = [len(_x) for _x in Elliott_patterns]\n",
    "    print(f'> Data {sum(n_spc)} samples')\n",
    "    print('> Samples per class :',n_spc)\n",
    "\n",
    "    return Elliott_patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _________________________ Experiment _________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Load Training set and Test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 5 # number of class\n",
    "\n",
    "print('Training set')\n",
    "training_path = '.\\Dataset\\\\Elliott_training_set.csv'\n",
    "X_train = load_dataset(training_path, C)\n",
    "\n",
    "print('\\nTest set')\n",
    "test_path = '.\\Dataset\\\\Elliott_test_set.csv'\n",
    "X_test = load_dataset(test_path, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_bins = 8\n",
    "S_train = String_representation(X_train, n_bins)\n",
    "S_test = String_representation(X_test, n_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training (Create prototype for each classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC = []\n",
    "cluster = [45, 30, 40, 35, 20]\n",
    "\n",
    "start = time.time()\n",
    "for i in range(C):\n",
    "    print(f'\\n<Class {i+1}>')\n",
    "    # C = number of prototype(that you want) in each class\n",
    "    SC.append(StringGrammarClustering(S_train[i], C = cluster[i], m = 2, eta = 2, a = 0.1, b = 0.16))\n",
    "end = time.time()\n",
    "print('time:', datetime.timedelta(seconds=end-start),end='\\n\\n')\n",
    "print('# Photptypes per class :', [len(sc) for sc in SC])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = FKNN(SC, S_test, C, K = 1, m = 2)\n",
    "# print(pred)\n",
    "print('accuracy :', accuracy(pred, C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = FKNN(SC, S_test, C, K = 3, m = 2)\n",
    "print('accuracy :', accuracy(pred, C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = FKNN(SC, S_test, C, K = 5, m = 2)\n",
    "print('accuracy :', accuracy(pred, C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = FKNN(SC, S_test, C, K = 7, m = 2)\n",
    "print('accuracy :', accuracy(pred, C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = FKNN(SC, S_test, C, K = 9, m = 2)\n",
    "print('accuracy :', accuracy(pred, C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = FKNN(SC, S_train, C, K = 1, m = 2)\n",
    "print('accuracy :', accuracy(pred, C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = FKNN(SC, S_train, C, K = 3, m = 2)\n",
    "print('accuracy :', accuracy(pred, C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = FKNN(SC, S_train, C, K = 5, m = 2)\n",
    "print('accuracy :', accuracy(pred, C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = FKNN(SC, S_train, C, K = 7, m = 2)\n",
    "print('accuracy :', accuracy(pred, C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"multiprototype_Elliott.csv\", 'w', encoding='UTF8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for i in range(C):\n",
    "            for j in range(len(SC[i])):\n",
    "                prototype = \"\".join(SC[i][j])\n",
    "                writer.writerow([i,prototype])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
