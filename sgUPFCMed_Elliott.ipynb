{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, string, time, datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randrange, shuffle\n",
    "from enchant.utils import levenshtein # pip install pyenchant\n",
    "from pyts.approximation import SymbolicAggregateApproximation # pip install pyts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _________________________ Algorithms _________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def String_representation(X, n_bins):\n",
    "    \n",
    "    # normalization\n",
    "    X_norm = [(Xi - Xi.mean())/Xi.std() for Xi in X]\n",
    "    \n",
    "    # Symbolic Aggregate Approximation\n",
    "    S = []\n",
    "    sax = SymbolicAggregateApproximation(n_bins=n_bins, strategy='normal')\n",
    "    for xs in X_norm:\n",
    "        S.append(''.join(sax.fit_transform([xs])[0]))\n",
    "    return S.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String grammar clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StringGrammarClustering(S, C, V_pos, m, eta, a, b): # normally (m , eta > 1)  (beta ,a , b > 0)\n",
    "    \n",
    "    N = len(S) # Number of string\n",
    "\n",
    "    print('<Initial>')\n",
    "    print('V_pos =', V_pos)\n",
    "    print('\\n<Processing>')\n",
    "    \n",
    "    Lev = [[0]*N for _ in range(N)]\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i <= j:\n",
    "                Lev[i][j] = levenshtein(S[i],S[j])\n",
    "            else:\n",
    "                Lev[i][j] = Lev[j][i]\n",
    "    \n",
    "    # Compute beta using fuzzy median equation (3)\n",
    "    Med_pos = np.array([sum([Lev[j][k] for k in range(N)]) for j in range(N)]).argmin()\n",
    "    beta = sum([Lev[Med_pos][k] for k in range(N)])/N \n",
    "    \n",
    "    epoch = 1\n",
    "    while True:\n",
    "        # Compute Levenshtein distance between input string j and cluster prototype i (Lev(s_j, sc_i))\n",
    "#         Lev = [[levenshtein(s_j, sc_i) for s_j in S] for sc_i in V]\n",
    "        \n",
    "        U = [[0]*N for _c in range(C)] # membership matrix [u_ik]_CxN\n",
    "        T = [[0]*N for _c in range(C)] # possibilistic matrix [t_ik]_CxN\n",
    "        \n",
    "        # Update membership and possibilistic\n",
    "        for i in range(C):\n",
    "            for k in range(N):    \n",
    "                \n",
    "                # Update membership value using equation (5)\n",
    "                if k not in V_pos: # string s_k is not prototype(V)\n",
    "                    U[i][k] = 1/sum([(Lev[V_pos[i]][k]/Lev[V_pos[j]][k])**(1/(m-1)) for j in range(C)])\n",
    "\n",
    "                # Update possibilistic value using equation (6)\n",
    "                T[i][k] = math.exp(-b * eta * math.sqrt(C) * Lev[V_pos[i]][k] / beta)\n",
    "            \n",
    "            # Set membership value sc_i = 1 (prototype)\n",
    "            U[i][V_pos[i]] = 1\n",
    "\n",
    "        # Update center string of each cluster i (sc_i) using equation (10)\n",
    "        V_pos_updated = [np.array([sum([(a*U[i][k]**m + b*T[i][k]**eta)*Lev[j][k] for k in range(N)]) for j in range(N)]).argmin() for i in range(C)]\n",
    "        \n",
    "        print('epoch', epoch, end=': ')\n",
    "        if V_pos_updated == V_pos:\n",
    "            print('<V not change>\\n')\n",
    "            # Multi-prototypes generation\n",
    "            SC = [[sc for j, sc in enumerate(S_train) if np.array([U[k][j] for k in range(C)]).argmax() == i] for i in range(C)]\n",
    "            return SC\n",
    "        else:\n",
    "            print('V_pos =', V_pos_updated)\n",
    "        \n",
    "        V_pos = V_pos_updated.copy()\n",
    "        epoch += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FKNN Classifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FKNN(SC, S_pred, C, K = 3):\n",
    "    m = 2\n",
    "    pred = []\n",
    "    for _s in S_pred:\n",
    "        \n",
    "        # lowest levenshtein distance K prototypes\n",
    "        lowest = []\n",
    "        Lev = [[levenshtein(_s, sc_ij) for sc_ij in sc_i] for sc_i in SC]\n",
    "        for _ in range(K):\n",
    "            lev_min = float('inf')\n",
    "            lev_class, lev_idx = -1, -1\n",
    "            for i in range(len(Lev)):\n",
    "                for j in range(len(Lev[i])):\n",
    "                    if Lev[i][j] < lev_min:\n",
    "                        lev_min = Lev[i][j]\n",
    "                        lev_class = i\n",
    "                        lev_idx = j\n",
    "            lowest.append((lev_class, lev_idx))\n",
    "            Lev[lev_class][lev_idx] = float('inf')\n",
    "\n",
    "        # class prediction\n",
    "        prob = []\n",
    "        for _k in range(K):\n",
    "            dividend, divisor = 0, 0\n",
    "            for (i, j) in lowest:\n",
    "                lev = levenshtein(SC[i][j], _s)\n",
    "                if not lev == 0:\n",
    "                    eq = (1/lev)**(1/(m-1))\n",
    "                else:\n",
    "                    eq = 1\n",
    "                \n",
    "                divisor += eq\n",
    "                if lowest[_k][0] == i:\n",
    "                    dividend += eq\n",
    "            prob.append(dividend/divisor)\n",
    "        pred.append(lowest[np.array(prob).argmax()][0])            \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _________________________ Experiment _________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset\n",
    "File Header : [Date, Open, High, Low, Close, Adj Close, Volume]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples per class : [98, 40, 64, 37, 29]\n",
      "Train :  248 samples\n",
      "Test :  20 samples\n"
     ]
    }
   ],
   "source": [
    "stocks = ['DELTA', 'HANA', 'KCE', 'NEX', 'TEAM', 'ADVANC', 'AIT', 'DTAC', 'FORTH',\n",
    "'HUMAN', 'ILINK', 'INET', 'JAS', 'JMART', 'MFEC', 'SAMART', 'SIS', 'SVOA', 'TRUE']\n",
    "\n",
    "X = [[] for _ in range(5)] # Elliott patterns\n",
    "\n",
    "for stock in stocks:\n",
    "    pattern = []\n",
    "    file = open('.\\Dataset\\\\' + stock +'_Elliott.csv')\n",
    "    data = file.read().split()\n",
    "    data = [d.split(',') for d in data]\n",
    "\n",
    "    for i, ds in enumerate(data):\n",
    "        if len(ds) == 2:\n",
    "            if not pattern == []:\n",
    "                X[_y].append(np.array(pattern))\n",
    "            pattern = []\n",
    "            \n",
    "            # for 5 classes recognition\n",
    "            _y = int(ds[1]) - 1 # class number\n",
    "            \n",
    "            # for 2 classes recognition\n",
    "#             if int(ds[1]) < 2:\n",
    "#                 _y = 0\n",
    "#             else:\n",
    "#                 _y = 1\n",
    "            \n",
    "        elif i == len(data) - 1:\n",
    "            X[_y].append(np.array(pattern))\n",
    "            pattern = []\n",
    "        else:\n",
    "#             pattern.append(float(ds[4])) # Close price\n",
    "            pattern.append(float(ds[2])) # High price\n",
    "            pattern.append(float(ds[3])) # Low Price\n",
    "            \n",
    "X = [[np.log(X[i][j]) for j in range(len(X[i])) if len(X[i][j]) <= 400] for i in range(len(X))]\n",
    "\n",
    "C = len(X) # number of class\n",
    "for i in range(C):\n",
    "    shuffle(X[i])\n",
    "\n",
    "n_spc = [len(_x) for _x in X]\n",
    "train_spc = [n-4 for n in n_spc]\n",
    "print('Samples per class :',n_spc)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = [], [], [], []\n",
    "for i in range(C):\n",
    "    X_train += X[i][:train_spc[i]]\n",
    "    Y_train += [i]*(train_spc[i])\n",
    "    X_test += X[i][train_spc[i]:]\n",
    "    Y_test += [i]*(n_spc[i]-train_spc[i])\n",
    "\n",
    "print('Train : ',len(X_train), 'samples')\n",
    "print('Test : ',len(X_test), 'samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_bins = 7\n",
    "S_train = String_representation(X_train, n_bins)\n",
    "S_test = String_representation(X_test, n_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Initial>\n",
      "V_pos = [93, 129, 189, 222, 247]\n",
      "\n",
      "<Processing>\n",
      "epoch 1: <V not change>\n",
      "\n",
      "time: 0:04:38.713217\n",
      "\n",
      "# Photptypes per class : [60, 56, 24, 81, 27]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "SC = StringGrammarClustering(S_train, C, V_pos=[sum(train_spc[:i+1])-1 for i in range(C)], m = 2, eta = 2, a = 1, b = 1)\n",
    "end = time.time()\n",
    "print('time:', datetime.timedelta(seconds=end-start),end='\\n\\n')\n",
    "print('# Photptypes per class :', [len(sc) for sc in SC])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_test : [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4]\n",
      "pred   : [0, 0, 3, 0, 3, 0, 3, 3, 1, 0, 1, 3, 3, 3, 3, 3, 4, 3, 3, 4]\n",
      "accuracy : 45.0\n"
     ]
    }
   ],
   "source": [
    "pred = FKNN(SC, S_test, C, K = 3)\n",
    "print('Y_test :', Y_test)\n",
    "print('pred   :', pred)\n",
    "print('accuracy :', round(sum([1 for i in range(len(pred)) if pred[i] == Y_test[i]])/len(pred)*100, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without Training (SAX to FKNN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_test : [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4]\n",
      "pred   : [1, 0, 2, 0, 1, 1, 0, 0, 3, 0, 0, 2, 0, 3, 0, 0, 4, 2, 3, 2]\n",
      "accuracy : 35.0\n"
     ]
    }
   ],
   "source": [
    "sc_spc = [0] + train_spc\n",
    "SC2 = [S_train[sum(sc_spc[:i]):sum(sc_spc[:i+1])] for i in range(1,C+1)]\n",
    "# SC2 = [SC2[i][:min(train_spc)] for i in range(C)]\n",
    "pred = FKNN(SC2, S_test, C, K = 5)\n",
    "print('Y_test :', Y_test)\n",
    "print('pred   :', pred)\n",
    "print('accuracy :', round(sum([1 for i in range(len(pred)) if pred[i] == Y_test[i]])/len(pred)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
