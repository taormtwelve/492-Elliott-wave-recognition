{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, string\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randrange, shuffle\n",
    "from enchant.utils import levenshtein # pip install pyenchant\n",
    "from pyts.approximation import PiecewiseAggregateApproximation, SymbolicAggregateApproximation # pip install pyts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples per class : [118, 55, 74, 47, 30]\n"
     ]
    }
   ],
   "source": [
    "stocks = ['DELTA', 'HANA', 'KCE', 'NEX', 'TEAM', 'ADVANC', 'AIT', 'DTAC', 'FORTH',\n",
    "'HUMAN', 'ILINK', 'INET', 'JAS', 'JMART', 'MFEC', 'SAMART', 'SIS', 'SVOA', 'TRUE']\n",
    "\n",
    "X = [[] for _ in range(5)] # Elliott patterns\n",
    "Y = [] # Elliott classes\n",
    "for stock in stocks:\n",
    "    pattern = []\n",
    "    file = open('.\\Dataset\\\\' + stock +'_Elliott.csv')\n",
    "    data = file.read().split()\n",
    "    data = [d.split(',') for d in data]\n",
    "\n",
    "    for i, ds in enumerate(data):\n",
    "        if len(ds) == 2 or i == len(data) - 1:\n",
    "\n",
    "            if not i == len(data) - 1:\n",
    "                _y = int(ds[1]) - 1 # class number\n",
    "\n",
    "            if not i == 0:\n",
    "                X[_y].append(np.array(pattern))\n",
    "                pattern = []\n",
    "        else:\n",
    "            pattern.append(float(ds[4])) \n",
    "\n",
    "C = len(X) # number of class\n",
    "for i in range(C):\n",
    "    shuffle(X[i])\n",
    "    \n",
    "n_spc = [len(_x) for _x in X]\n",
    "print('Samples per class :',n_spc)\n",
    "\n",
    "X_train, X_test = [], []\n",
    "for i in range(C):\n",
    "    X_train += X[i]\n",
    "    Y += [i]*n_spc[i]\n",
    "#     X_test += X[i][spc:spc + 10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def String_representation(X):\n",
    "    # normalization\n",
    "    X_norm = [(Xi - Xi.mean())/Xi.std() for Xi in X]\n",
    "\n",
    "    X_paa = []\n",
    "    S = [] # set of N strings\n",
    "    for T in X_norm:\n",
    "        n = len(T) # length of time series\n",
    "        w = 2\n",
    "        n_bins = 8\n",
    "\n",
    "        # PAA (Piecewise Aggregate Approximation)\n",
    "        paa = PiecewiseAggregateApproximation(window_size=w)\n",
    "        X_paa.append(paa.transform([T])[0])\n",
    "\n",
    "        # SAX (Symbolic Aggregate approXimation)\n",
    "        sax = SymbolicAggregateApproximation(n_bins=n_bins, strategy='normal')\n",
    "        st = ''\n",
    "        for s in sax.fit_transform([X_paa[-1]])[0]:\n",
    "            st += s\n",
    "        S.append(st)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = String_representation(X_train)\n",
    "# S_test = String_representation(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String grammar clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StringGrammarClustering(S, C, V_pos):\n",
    "    \n",
    "    N = len(S) # Number of string\n",
    "    m, eta, a, b = 2, 2, 2, 0.5 # normally m > 1, eta > 1, beta > 0, a > 0, b > 0\n",
    "    sigma = string.ascii_lowercase[:C]\n",
    "\n",
    "    # Initialize string prototypes for all C classes\n",
    "    V = [S[i] for i in V_pos]\n",
    "\n",
    "    print('<---------- V initial ---------->')\n",
    "    for i, sc in enumerate(V):\n",
    "        print(f'sc_{i+1} : {sc}')\n",
    "    print('\\n<---------- V processing ---------->')\n",
    "\n",
    "    # Compute beta using fuzzy median equation (3)\n",
    "    Med = S[np.array([sum([levenshtein(s_j,s_k) for s_k in S]) for s_j in S]).argmin()]\n",
    "    beta = sum([levenshtein(Med, s_k) for s_k in S])/N\n",
    "    \n",
    "    while True:\n",
    "        U = [[0]*N for _c in range(C)] # membership matrix [u_ik]_CxN\n",
    "        T = [[0]*N for _c in range(C)] # possibilistic matrix [t_ik]_CxN\n",
    "        \n",
    "        # Compute Levenshtein distance between input string j and cluster prototype i (Lev(s_j, sc_i))\n",
    "        Lev = [[levenshtein(s_j, sc_i) for s_j in S] for sc_i in V]\n",
    "        \n",
    "        # Update membership and possibilistic\n",
    "        for i in range(C):\n",
    "            for k in range(N):    \n",
    "                \n",
    "                # Update membership value using equation (5)\n",
    "                if k not in V_pos: # string s_k is not phototype(V) \n",
    "                    U[i][k] = 1/sum([(Lev[i][k]/Lev[j][k])**(1/(m-1)) for j in range(C) if Lev[j][k] > 0])\n",
    "\n",
    "                # Update possibilistic value using equation (6)\n",
    "                T[i][k] = math.e**(-(b * eta * math.sqrt(C) * Lev[i][k]) / beta)\n",
    "            \n",
    "            # Set membership value sc_i = 1 (phototype)\n",
    "            U[i][V_pos[i]] = 1\n",
    "\n",
    "        # Update center string of each cluster i (sc_i) using equation (10)\n",
    "        V_pos = [np.array([sum([(a*U[i][k]**m + b*T[i][k]**eta)*levenshtein(S[j],S[k]) for k in range(N)]) for j in range(N)]).argmin() for i in range(C)]\n",
    "        V_updated = [S[pos] for pos in V_pos]\n",
    "        \n",
    "        if V_updated == V:\n",
    "            print('>>>> V not change <<<<')\n",
    "            print('>>>>     End!     <<<<\\n')\n",
    "            return U\n",
    "        V = V_updated.copy()\n",
    "        for i, sc in enumerate(V):\n",
    "            print(f'sc_{i+1} : {sc}')\n",
    "        print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<---------- V initial ---------->\n",
      "sc_1 : aaabdfedddhghgh\n",
      "sc_2 : cabbaabddeeedeedddccdefhhgehh\n",
      "sc_3 : abbbbcbbbbbbbbbbbcdddefffeefffhhhhhh\n",
      "sc_4 : aeceedcgh\n",
      "sc_5 : acddbcdfhh\n",
      "\n",
      "<---------- V processing ---------->\n",
      "sc_1 : aabbccdeffefhhh\n",
      "sc_2 : abbbbddddecddbcghhhh\n",
      "sc_3 : abbbbcbbbbbbbbbbbcdddefffeefffhhhhhh\n",
      "sc_4 : hhffeefedcaa\n",
      "sc_5 : acddbcdfhh\n",
      "\n",
      ">>>> V not change <<<<\n",
      ">>>>     End!     <<<<\n",
      "\n"
     ]
    }
   ],
   "source": [
    "U = StringGrammarClustering(S, C, V_pos=[n-1 for n in n_spc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-phototypes generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Photptypes per class : [45, 20, 128, 108, 23]\n"
     ]
    }
   ],
   "source": [
    "SC = [[sc for j, sc in enumerate(S) if np.array([U[k][j] for k in range(C)]).argmax() == i] for i in range(C)]\n",
    "print('Photptypes per class :', [len(sc) for sc in SC])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FKNN Classifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FKNN(SC, S_pred, C, K = 3):\n",
    "    m = 2\n",
    "    pred = []\n",
    "    for _s in S_pred:\n",
    "        \n",
    "        # lowest levenshtein distance K phototypes\n",
    "        lowest = []\n",
    "        Lev = [[levenshtein(_s, sc_ij) for sc_ij in sc_i] for sc_i in SC]\n",
    "        for _ in range(K):\n",
    "            lev_min = float('inf')\n",
    "            lev_class = -1\n",
    "            for i in range(len(Lev)):\n",
    "                for j in range(len(Lev[i])):\n",
    "                    if Lev[i][j] < lev_min:\n",
    "                        lev_min = Lev[i][j]\n",
    "                        lev_class = i\n",
    "                        lev_idx = j\n",
    "            lowest.append((lev_class, lev_idx))\n",
    "            Lev[lev_class][lev_idx] = float('inf')\n",
    "        \n",
    "        # class prediction\n",
    "        prob = []\n",
    "        for _k in range(K):\n",
    "            dividend, divisor = 0, 0\n",
    "            for (i, j) in lowest:\n",
    "                lev = levenshtein(SC[i][j], _s)\n",
    "                if lev != 0:\n",
    "                    eq = (1/lev)**(1/(m-1))\n",
    "                else:\n",
    "                    eq = 1\n",
    "                \n",
    "                divisor += eq\n",
    "                if lowest[_k][0] == i:\n",
    "                    dividend += eq\n",
    "            prob.append(dividend/divisor)\n",
    "        pred.append(lowest[np.array(prob).argmax()][0])\n",
    "                \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 3, 2, 3, 2, 3, 2, 3, 3, 2, 3, 3, 1, 3, 3, 3, 3, 3, 3, 0, 2, 2, 3, 3, 2, 0, 4, 3, 4, 2, 0, 2, 0, 3, 3, 3, 1, 4, 2, 2, 0, 3, 3, 2, 3, 4, 3, 3, 2, 3, 2, 0, 3, 1, 2, 0, 2, 0, 2, 2, 3, 2, 2, 2, 3, 2, 4, 3, 3, 3, 3, 4, 2, 3, 2, 3, 2, 3, 2, 3, 0, 2, 2, 3, 3, 4, 2, 2, 2, 3, 2, 2, 0, 0, 2, 2, 2, 2, 2, 3, 2, 0, 2, 3, 3, 3, 2, 4, 2, 2, 2, 0, 2, 3, 2, 2, 0, 0, 2, 2, 4, 2, 3, 3, 2, 0, 2, 2, 1, 2, 0, 4, 2, 2, 3, 4, 0, 0, 0, 3, 2, 2, 2, 3, 2, 3, 0, 3, 2, 0, 4, 4, 4, 3, 3, 3, 3, 4, 1, 2, 1, 2, 3, 2, 0, 3, 3, 0, 3, 3, 0, 2, 2, 4, 2, 2, 2, 0, 4, 3, 3, 1, 2, 0, 0, 2, 2, 1, 3, 3, 3, 2, 2, 2, 2, 0, 3, 2, 0, 1, 2, 4, 0, 2, 2, 3, 3, 3, 0, 3, 2, 2, 3, 2, 0, 2, 1, 1, 3, 3, 2, 0, 3, 2, 3, 2, 2, 2, 3, 2, 2, 3, 3, 2, 2, 2, 4, 2, 2, 2, 2, 3, 2, 1, 2, 2, 2, 0, 2, 3, 3, 2, 2, 2, 3, 2, 2, 2, 3, 2, 0, 2, 2, 2, 2, 2, 3, 2, 3, 2, 0, 2, 1, 3, 0, 0, 2, 3, 3, 2, 0, 1, 4, 2, 3, 3, 0, 3, 0, 3, 3, 3, 2, 3, 3, 0, 1, 3, 3, 1, 4, 1, 3, 4, 3, 2, 0, 3, 2, 4, 0, 2, 2, 1, 1, 2, 3, 3, 3, 3, 3, 2, 1]\n",
      "accuracy : 21.91\n"
     ]
    }
   ],
   "source": [
    "pred = FKNN(SC, S, C, K = 3)\n",
    "print(pred)\n",
    "print('accuracy :', round(sum([1 for i in range(len(pred)) if pred[i] == Y[i]])/len(pred)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
